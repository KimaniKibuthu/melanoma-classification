{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SIIM-ISIC Melanoma Classification\nSkin cancer is the most prevalent type of cancer. Melanoma, specifically, is responsible for 75% of skin cancer deaths, despite being the least common skin cancer. The American Cancer Society estimates over 100,000 new melanoma cases will be diagnosed in 2020. It's also expected that almost 7,000 people will die from the disease. As with other cancers, early and accurate detection—potentially aided by data science—can make treatment more effective.\n\nCurrently, dermatologists evaluate every one of a patient's moles to identify outlier lesions or “ugly ducklings” that are most likely to be melanoma. Existing AI approaches have not adequately considered this clinical frame of reference. Dermatologists could enhance their diagnostic accuracy if detection algorithms take into account “contextual” images within the same patient to determine which images represent a melanoma. If successful, classifiers would be more accurate and could better support dermatological clinic work.\n\nAs the leading healthcare organization for informatics in medical imaging, the Society for Imaging Informatics in Medicine (SIIM)'s mission is to advance medical imaging informatics through education, research, and innovation in a multi-disciplinary community. SIIM is joined by the International Skin Imaging Collaboration (ISIC), an international effort to improve melanoma diagnosis. The ISIC Archive contains the largest publicly available collection of quality-controlled dermoscopic images of skin lesions.\n\nIn this competition, you’ll identify melanoma in images of skin lesions. In particular, you’ll use images within the same patient and determine which are likely to represent a melanoma. Using patient-level contextual information may help the development of image analysis tools, which could better support clinical dermatologists.\n\nMelanoma is a deadly disease, but if caught early, most melanomas can be cured with minor surgery. Image analysis tools that automate the diagnosis of melanoma will improve dermatologists' diagnostic accuracy. Better detection of melanoma has the opportunity to positively impact millions of people.","metadata":{"id":"ny4dDarbc8Ju"}},{"cell_type":"markdown","source":"# Import the necessary libraries","metadata":{"id":"T08pHMx_dJ1x"}},{"cell_type":"code","source":"# General libraries\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split \n \n# Modelling libraries \nimport tensorflow as tf \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras import Model, Sequential \nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, GlobalAveragePooling2D \nfrom tensorflow.keras.applications import InceptionV3, VGG16, MobileNet","metadata":{"id":"A5oFCgG9daN2","execution":{"iopub.status.busy":"2021-08-02T07:42:36.048794Z","iopub.execute_input":"2021-08-02T07:42:36.049273Z","iopub.status.idle":"2021-08-02T07:42:42.585654Z","shell.execute_reply.started":"2021-08-02T07:42:36.049151Z","shell.execute_reply":"2021-08-02T07:42:42.584479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Variables \n \nTARGET_SIZE = 256 \nTEST_SIZE = 0.5 \nBATCH_SIZE = 64 \nRANDOM_STATE = 42 \nEPOCHS = 5 \nLR = 0.0001 \n","metadata":{"id":"Javd1V3mdiBH","execution":{"iopub.status.busy":"2021-08-02T07:42:42.589712Z","iopub.execute_input":"2021-08-02T07:42:42.590056Z","iopub.status.idle":"2021-08-02T07:42:42.597816Z","shell.execute_reply.started":"2021-08-02T07:42:42.590024Z","shell.execute_reply":"2021-08-02T07:42:42.596593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Obtainance","metadata":{"id":"tbKPrtUOeJe7"}},{"cell_type":"code","source":"train = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv') \ntest = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv') \nsubmission = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')","metadata":{"id":"xXB5xUAon6jF","execution":{"iopub.status.busy":"2021-08-02T07:42:42.600232Z","iopub.execute_input":"2021-08-02T07:42:42.601091Z","iopub.status.idle":"2021-08-02T07:42:42.723434Z","shell.execute_reply.started":"2021-08-02T07:42:42.60103Z","shell.execute_reply":"2021-08-02T07:42:42.722423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{"id":"2xSYmzprnxAb"}},{"cell_type":"markdown","source":"**General Exploration**","metadata":{"id":"TWytx7GonzLh"}},{"cell_type":"code","source":"# Train csv \n \ntrain.head()","metadata":{"id":"8eA6vtWklI40","execution":{"iopub.status.busy":"2021-08-02T07:42:42.725547Z","iopub.execute_input":"2021-08-02T07:42:42.726023Z","iopub.status.idle":"2021-08-02T07:42:42.762296Z","shell.execute_reply.started":"2021-08-02T07:42:42.72598Z","shell.execute_reply":"2021-08-02T07:42:42.760732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# See distribution of target \nplt.figure(figsize=(12, 8)) \nsns.countplot(x='target', data=train, palette='husl');","metadata":{"id":"cr04iJ9ZoJxu","execution":{"iopub.status.busy":"2021-08-02T07:42:42.763902Z","iopub.execute_input":"2021-08-02T07:42:42.764358Z","iopub.status.idle":"2021-08-02T07:42:42.964072Z","shell.execute_reply.started":"2021-08-02T07:42:42.764316Z","shell.execute_reply":"2021-08-02T07:42:42.962694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confirm the number \nprint(train.target.value_counts()) \nprint('-'*20) \ntrain.target.value_counts(normalize=True)","metadata":{"id":"B9fbDquypGMT","execution":{"iopub.status.busy":"2021-08-02T07:42:42.966055Z","iopub.execute_input":"2021-08-02T07:42:42.966519Z","iopub.status.idle":"2021-08-02T07:42:42.998476Z","shell.execute_reply.started":"2021-08-02T07:42:42.966471Z","shell.execute_reply":"2021-08-02T07:42:42.997409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add jpg extension to images \ntrain['images'] = train['image_name'] + '.jpg' \n \ntrain.head()","metadata":{"id":"f4ZciygbqDfn","execution":{"iopub.status.busy":"2021-08-02T07:42:43.000014Z","iopub.execute_input":"2021-08-02T07:42:43.000511Z","iopub.status.idle":"2021-08-02T07:42:43.026355Z","shell.execute_reply.started":"2021-08-02T07:42:43.000468Z","shell.execute_reply":"2021-08-02T07:42:43.024813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is great imbalance. We need to take care of this.","metadata":{"id":"JhXLjWaMpVdL"}},{"cell_type":"markdown","source":"**Dealing with imbalance**","metadata":{"id":"E5VCE6x9prGF"}},{"cell_type":"code","source":"# Initialize weights \nWEIGHTS = { \n    0:0.51, \n    1:28.36 \n} \n \n# Initialize bias \nbias = tf.keras.initializers.Constant(np.log([584/32542]))","metadata":{"id":"7zR1TpF7pUAp","execution":{"iopub.status.busy":"2021-08-02T07:42:43.031246Z","iopub.execute_input":"2021-08-02T07:42:43.032193Z","iopub.status.idle":"2021-08-02T07:42:43.038506Z","shell.execute_reply.started":"2021-08-02T07:42:43.032146Z","shell.execute_reply":"2021-08-02T07:42:43.037138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**View the data**","metadata":{"id":"jxFxCgxMsRe2"}},{"cell_type":"code","source":"train_path = '../input/siim-isic-melanoma-classification/jpeg/train'\ntest_path = '../input/siim-isic-melanoma-classification/jpeg/test'","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:42:43.041701Z","iopub.execute_input":"2021-08-02T07:42:43.042262Z","iopub.status.idle":"2021-08-02T07:42:43.051121Z","shell.execute_reply.started":"2021-08-02T07:42:43.042178Z","shell.execute_reply":"2021-08-02T07:42:43.049906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(label, data, path): \n    # Get images  \n    df = data.loc[data['target'] == label] \n    images = df['images'].values \n \n    # Extract 16 random images from it \n    random_images = [np.random.choice(images) for i in range(9)] \n \n    # Adjust the size of your images \n    plt.figure(figsize=(16,12)) \n \n    # Iterate and plot random images \n    for i in range(9): \n        plt.subplot(3,3, i + 1) \n        img = plt.imread(os.path.join(path, random_images[i])) \n         \n        try: \n          plt.imshow(img, cmap='gray') \n          plt.axis('off') \n        except FileNotFoundError: \n          pass \n \n    # Adjust subplot parameters to give specified padding \n    plt.tight_layout() ","metadata":{"id":"ESvYkHJcsQBs","execution":{"iopub.status.busy":"2021-08-02T07:42:43.055319Z","iopub.execute_input":"2021-08-02T07:42:43.055698Z","iopub.status.idle":"2021-08-02T07:42:43.06675Z","shell.execute_reply.started":"2021-08-02T07:42:43.055649Z","shell.execute_reply":"2021-08-02T07:42:43.065418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Melanoma positive \nshow_images(1, train, train_path)","metadata":{"id":"gcVCE6o0srWn","execution":{"iopub.status.busy":"2021-08-02T07:42:43.068567Z","iopub.execute_input":"2021-08-02T07:42:43.069233Z","iopub.status.idle":"2021-08-02T07:42:57.628411Z","shell.execute_reply.started":"2021-08-02T07:42:43.06916Z","shell.execute_reply":"2021-08-02T07:42:57.625546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Free from cancer \nshow_images(0, train, train_path)","metadata":{"id":"b-7M30zbswmj","execution":{"iopub.status.busy":"2021-08-02T07:42:57.629686Z","iopub.execute_input":"2021-08-02T07:42:57.630138Z","iopub.status.idle":"2021-08-02T07:43:19.870711Z","shell.execute_reply.started":"2021-08-02T07:42:57.630071Z","shell.execute_reply":"2021-08-02T07:43:19.869469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create Generators**","metadata":{"id":"9XgqlWlntrwF"}},{"cell_type":"code","source":"# Convert target to string \ntrain['target'] = train['target'].astype(str)","metadata":{"id":"aO89X-tjv3Zp","execution":{"iopub.status.busy":"2021-08-02T07:43:19.872428Z","iopub.execute_input":"2021-08-02T07:43:19.872995Z","iopub.status.idle":"2021-08-02T07:43:19.938975Z","shell.execute_reply.started":"2021-08-02T07:43:19.872953Z","shell.execute_reply":"2021-08-02T07:43:19.937887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data \n \ntrain_set, val_set = train_test_split(train, \n                                      test_size=0.1, \n                                      random_state=RANDOM_STATE, \n                                      stratify=train['target']) \n \ntrain_set = train_set.reset_index(drop=True) \nval_set = val_set.reset_index(drop=True)","metadata":{"id":"1TX3wslwtn6s","execution":{"iopub.status.busy":"2021-08-02T07:43:19.941559Z","iopub.execute_input":"2021-08-02T07:43:19.942301Z","iopub.status.idle":"2021-08-02T07:43:20.021773Z","shell.execute_reply.started":"2021-08-02T07:43:19.942252Z","shell.execute_reply":"2021-08-02T07:43:20.020655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator( \n    brightness_range = [0.8, 1.5],  \n    horizontal_flip = True, \n    vertical_flip = True, \n    preprocessing_function=tf.keras.applications.mobilenet.preprocess_input \n    ) \n \nval_datagen = ImageDataGenerator( \n    preprocessing_function=tf.keras.applications.mobilenet.preprocess_input \n    )","metadata":{"id":"e7WlHi4RurBU","execution":{"iopub.status.busy":"2021-08-02T07:43:20.025183Z","iopub.execute_input":"2021-08-02T07:43:20.025641Z","iopub.status.idle":"2021-08-02T07:43:20.032815Z","shell.execute_reply.started":"2021-08-02T07:43:20.025601Z","shell.execute_reply":"2021-08-02T07:43:20.031133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate flows\ntrain_flow = train_datagen.flow_from_dataframe( \n    train_set, \n    train_path, \n    x_col = 'images', \n    y_col = 'target', \n    target_size = (TARGET_SIZE, TARGET_SIZE), \n    class_mode = 'binary', \n    batch_size = BATCH_SIZE \n \n) \n \n \nval_flow = val_datagen.flow_from_dataframe( \n    val_set, \n    train_path, \n    x_col = 'images', \n    y_col = 'target', \n    target_size = (TARGET_SIZE, TARGET_SIZE), \n    class_mode = 'binary', \n    batch_size = BATCH_SIZE \n \n)","metadata":{"id":"K43WSiwXvRtE","execution":{"iopub.status.busy":"2021-08-02T07:43:20.034871Z","iopub.execute_input":"2021-08-02T07:43:20.03583Z","iopub.status.idle":"2021-08-02T07:44:17.421535Z","shell.execute_reply.started":"2021-08-02T07:43:20.035772Z","shell.execute_reply":"2021-08-02T07:44:17.419816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize an image \nx_batch, y_batch = next(train_flow) \nfor i in range (0,6): \n    image = x_batch[i] \n    plt.imshow(image) \n    plt.show()","metadata":{"id":"mQmt6YBhwZWj","execution":{"iopub.status.busy":"2021-08-02T07:44:17.427448Z","iopub.execute_input":"2021-08-02T07:44:17.427909Z","iopub.status.idle":"2021-08-02T07:44:34.374455Z","shell.execute_reply.started":"2021-08-02T07:44:17.42786Z","shell.execute_reply":"2021-08-02T07:44:34.373075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Development","metadata":{"id":"NyUynEaPwJXg"}},{"cell_type":"code","source":"def create_model(): \n \n    global bias  \n  # Build model \n    mobilenet = MobileNet(include_top=False,  \n                          input_shape=(TARGET_SIZE, TARGET_SIZE, 3), \n                          weights='imagenet') \n   \n    for layer in mobilenet.layers: \n      layer.trainable = True \n \n    model = Sequential([ \n                      mobilenet, \n                      GlobalAveragePooling2D(), \n                      #Flatten(), \n                      #Dense(256, activation = 'relu',  \n                           #bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01,  \n                           #                                            l2=0.001)), \n                      #Dropout(0.5), \n                      Dense(32, activation = 'relu'),\n                          #bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, \n                           #                                            l2=0.001)), \n                      Dropout(0.5), \n                      Dense(1, activation = 'sigmoid', bias_initializer = bias) \n    ]) \n \n  # Instantiate learning rate and optimizer \n \n    adam = tf.keras.optimizers.Adam(LR) \n \n    auc = tf.keras.metrics.AUC( num_thresholds=200, curve='ROC', \n                               summation_method='interpolation', name='auc') \n \n    precision = tf.keras.metrics.Precision(name='precision'), \n    recall = tf.keras.metrics.Recall(name='recall') \n    metrics = [auc, precision, recall] \n \n  # Compile model \n    model.compile(loss = 'binary_crossentropy', \n                optimizer = adam, \n                metrics = metrics) \n   \n    return model","metadata":{"id":"eURMUcoSvtIH","execution":{"iopub.status.busy":"2021-08-02T07:48:39.616909Z","iopub.execute_input":"2021-08-02T07:48:39.617308Z","iopub.status.idle":"2021-08-02T07:48:39.627457Z","shell.execute_reply.started":"2021-08-02T07:48:39.617277Z","shell.execute_reply":"2021-08-02T07:48:39.625697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()","metadata":{"id":"D1x9fvWMx5dD","execution":{"iopub.status.busy":"2021-08-02T07:48:40.303179Z","iopub.execute_input":"2021-08-02T07:48:40.30372Z","iopub.status.idle":"2021-08-02T07:48:41.514253Z","shell.execute_reply.started":"2021-08-02T07:48:40.303685Z","shell.execute_reply":"2021-08-02T07:48:41.51268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:44:38.301158Z","iopub.execute_input":"2021-08-02T07:44:38.301615Z","iopub.status.idle":"2021-08-02T07:44:38.330191Z","shell.execute_reply.started":"2021-08-02T07:44:38.301574Z","shell.execute_reply":"2021-08-02T07:44:38.328289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_fitter(model): \n \n  # instantiate callbacks \n   \n  early_stopper = tf.keras.callbacks.EarlyStopping(monitor='val_auc', \n                                                 patience=5) \n \n  # reduce learning rate \n  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_auc', \n                                  factor = 0.1, \n                                  patience = 2, \n                                  min_lr = 1e-6, \n                                  mode = 'min', \n                                  verbose = 1) \n \n  callbacks = [early_stopper, reduce_lr] \n \n  # Train model \n  history = model.fit(train_flow, \n                    epochs=EPOCHS, \n                    steps_per_epoch=int(np.ceil(len(train_set)/BATCH_SIZE)), \n                    callbacks=callbacks, \n                    validation_data=val_flow, \n                    validation_steps=int(np.ceil(len(val_set)/BATCH_SIZE)), \n                    class_weight = WEIGHTS \n                    ) \n   \n  return history, model","metadata":{"id":"_yQyA_tExqzI","execution":{"iopub.status.busy":"2021-08-02T07:44:38.331894Z","iopub.execute_input":"2021-08-02T07:44:38.332381Z","iopub.status.idle":"2021-08-02T07:44:38.34163Z","shell.execute_reply.started":"2021-08-02T07:44:38.332339Z","shell.execute_reply":"2021-08-02T07:44:38.340044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history, model = model_fitter(model)","metadata":{"id":"-CQSzkz1yco2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"fqvZ7U2aysJ-"},"execution_count":null,"outputs":[]}]}